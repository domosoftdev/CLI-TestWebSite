#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Algorithme de Calcul de Score de Parking de Domaine.
Ce script peut √™tre ex√©cut√© de mani√®re autonome pour obtenir le score de parking d'un domaine.
"""

import argparse
import sys
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import dns.resolver
import uuid
import whois
from datetime import datetime, timedelta
import re

# --- CONSTANTES ---

KEYWORDS_FOR_SALE = list(set([
    "domain for sale", "domaine √† vendre", "buy this domain", "acheter ce domaine",
    "make an offer", "faire une offre", "this domain is available", "domain available",
    "premium domain", "inquire about this domain", "inquire now", "contact owner",
    "investment opportunity", "price negotiable", "best offer", "interested in this domain?",
    "domain marketplace", "acquire this domain", "domain broker", "purchase domain",
    "domain name sales", "get this domain", "domain for acquisition"
]))
KEYWORDS_PARKING_GENERIC = list(set([
    "domain parking", "parked domain", "sedo", "bodis", "dan.com", "afternic",
    "domain name", "related searches", "sponsored listings", "ads by",
    "coming soon", "en construction", "under construction", "this domain is parked",
    "future home of", "placeholder page", "work in progress", "site under development",
    "related search terms", "sponsored search ads", "parked free courtesy of",
    "this page is generated by", "no website is currently configured",
    "this domain has been reserved", "ads by google", "click here for more information",
    "web hosting by", "site not found", "default web page", "welcome to your new domain",
    "ionos", "ionos domain parking", "domcollect"
]))
KNOWN_PARKING_HOSTNAMES = [
    "sedo.com", "bodis.com", "dan.com", "afternic.com", "hugedomains.com",
    "uniregistry.com", "above.com", "parkingcrew.net", "domainsponsor.com",
    "domcollect.com"
]
KNOWN_PARKING_NAMESERVERS = [
    "sedoparking.com", "bodis.com", "parkingcrew.net", "above.com", "abovedomains.com",
    "uniregistrymarket.link", "huge-domains.com", "afternic.com", "dan.com"
]
KNOWN_PARKING_IP_RANGES = []
CSS_PARKING_KEYWORDS = ["parking", "parked", "for-sale", "placeholder"]

# --- FONCTIONS D'ANALYSE ---

def analyserContenu(domaine: str, verbose: bool = False) -> int:
    """Analyse le contenu HTTP d'un domaine. Score: 0-40."""
    if verbose: print("\n--- Analyse du Contenu (max 40 pts) ---")
    score = 0
    urls_a_tester = [f"https://www.{domaine}", f"https://{domaine}", f"http://{domaine}"]
    page_html, url_finale = "", ""
    session = requests.Session()
    session.max_redirects = 5
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}

    for url in urls_a_tester:
        try:
            if verbose: print(f"  [i] Test de l'URL : {url}")
            reponse = session.get(url, timeout=10, headers=headers)
            if reponse.status_code == 200:
                page_html, url_finale = reponse.text, reponse.url
                if verbose: print(f"  [+] Connexion r√©ussie √† : {url_finale}")
                break
        except requests.exceptions.RequestException as e:
            if verbose: print(f"  [!] √âchec de la connexion : {e}")
            continue

    if not page_html:
        if verbose: print("  [!] Impossible de r√©cup√©rer le contenu de la page. : +5 pts")
        return 5

    hostname_final = urlparse(url_finale).hostname
    if hostname_final:
        for parking_host in KNOWN_PARKING_HOSTNAMES:
            if hostname_final.endswith(parking_host):
                if verbose: print(f"  [+] Redirection vers un service de parking connu ({parking_host}) : +20 pts")
                score += 20
                break

    soup = BeautifulSoup(page_html, 'html.parser')

    # Analyse des mots-cl√©s dans le texte et les meta-tags
    lines = (line.strip() for line in soup.stripped_strings)
    all_text = " ".join(line.lower() for line in lines if line)
    for meta in soup.find_all('meta', attrs={'name': ['description', 'keywords']}):
        if meta.get('content'): all_text += " " + meta.get('content').lower()

    found_sale_keyword = False
    for keyword in KEYWORDS_FOR_SALE:
        if keyword in all_text:
            if verbose: print(f"  [+] Mot-cl√© de vente trouv√© ('{keyword}') : +10 pts")
            score += 10
            found_sale_keyword = True
            break
    if not found_sale_keyword and verbose: print("  [-] Aucun mot-cl√© de vente explicite trouv√©.")

    found_generic_keyword = False
    for keyword in KEYWORDS_PARKING_GENERIC:
        if keyword in all_text:
            if verbose: print(f"  [+] Mot-cl√© de parking g√©n√©rique trouv√© ('{keyword}') : +10 pts")
            score += 10
            found_generic_keyword = True
            break
    if not found_generic_keyword and verbose: print("  [-] Aucun mot-cl√© de parking g√©n√©rique trouv√©.")

    # üîç Analyse du titre
    if "<title>" in page_html.lower():
        try:
            title = page_html.lower().split("<title>")[1].split("</title>")[0]
            if any(t in title for t in ["domain for sale", "welcome", "buy now"]):
                if verbose: print(f"  [+] Titre suspect d√©tect√© ('{title}') : +5 pts")
                score += 5
        except Exception:
            pass

    # üñºÔ∏è Favicon g√©n√©rique
    if "favicon.ico" in page_html.lower():
        if verbose: print("  [+] Favicon g√©n√©rique d√©tect√© : +3 pts")
        score += 3

    # üìè Volume de texte faible
    if len(all_text.split()) < 100:
        if verbose: print("  [+] Volume de texte faible (<100 mots) : +5 pts")
        score += 5

    # Analyse des classes CSS
    found_css_keyword = False
    for element in soup.find_all(class_=True):
        for css_class in element["class"]:
            for keyword in CSS_PARKING_KEYWORDS:
                if keyword in css_class:
                    if verbose: print(f"  [+] Classe CSS de parking trouv√©e ('{css_class}') : +10 pts")
                    score += 10
                    found_css_keyword = True
                    break
            if found_css_keyword: break
        if found_css_keyword: break
    if not found_css_keyword and verbose: print("  [-] Aucune classe CSS de parking trouv√©e.")

    # Analyse des sources de script/iframe
    found_script_source = False
    for tag in soup.find_all(['script', 'iframe'], src=True):
        src = tag['src']
        try:
            src_domain = urlparse(src).hostname
            if src_domain:
                for parking_host in KNOWN_PARKING_HOSTNAMES:
                    if src_domain.endswith(parking_host):
                        if verbose: print(f"  [+] Source de script/iframe de parking trouv√©e ('{src_domain}') : +15 pts")
                        score += 15
                        found_script_source = True
                        break
        except Exception:
            continue
        if found_script_source: break
    if not found_script_source and verbose: print("  [-] Aucune source de script/iframe de parking trouv√©e.")

    return min(score, 40) # On plafonne le score de contenu √† 40

def analyserTechnique(domaine: str, verbose: bool = False) -> int:
    """Analyse les enregistrements DNS. Score: 0-30."""
    if verbose: print("\n--- Analyse Technique (max 30 pts) ---")
    score = 0
    resolver = dns.resolver.Resolver(configure=False)
    resolver.nameservers = ['8.8.8.8', '1.1.1.1']
    resolver.timeout, resolver.lifetime = 5, 5

    try:
        ns_records = resolver.resolve(domaine, 'NS')
        ns_match_found = False
        for record in ns_records:
            ns_str = str(record.target).lower()
            if verbose: print(f"  [i] Serveur de noms trouv√© : {ns_str.rstrip('.')}")
            for known_ns in KNOWN_PARKING_NAMESERVERS:
                if ns_str.startswith(known_ns.rstrip('.')) or ns_str.endswith(known_ns + '.'):
                    if verbose: print(f"  [+] Le serveur de noms correspond √† un service de parking connu ({known_ns}) : +15 pts")
                    score += 15
                    ns_match_found = True
                    break
            if ns_match_found: break
        if not ns_match_found and verbose: print("  [-] Aucun serveur de noms de parking connu trouv√©.")
    except Exception as e:
        if verbose: print(f"  [!] Erreur lors de la r√©solution NS : {e}")

    try:
        ip_racine_answers = resolver.resolve(domaine, 'A')
        ip_racine = {str(r) for r in ip_racine_answers}
        if verbose: print(f"  [i] Adresses IP trouv√©es pour {domaine} : {ip_racine}")
        sous_domaine_aleatoire = f"test-wildcard-{uuid.uuid4().hex[:8]}.{domaine}"
        ip_aleatoire_answers = resolver.resolve(sous_domaine_aleatoire, 'A')
        ip_aleatoire = {str(r) for r in ip_aleatoire_answers}
        if verbose: print(f"  [i] Adresses IP trouv√©es pour {sous_domaine_aleatoire} : {ip_aleatoire}")
        if ip_racine and ip_aleatoire == ip_racine:
            if verbose: print("  [+] Un enregistrement DNS Wildcard a √©t√© d√©tect√© : +5 pts")
            score += 5
        elif verbose: print("  [-] Pas de DNS Wildcard d√©tect√©.")
    except Exception as e:
        if verbose: print(f"  [!] Pas de DNS Wildcard d√©tect√© ou erreur : {e}")

    return score

def analyserContextuel(domaine: str, verbose: bool = False) -> int:
    """Analyse les donn√©es WHOIS. Score: 0-30."""
    if verbose: print("\n--- Analyse Contextuelle (max 30 pts) ---")
    score = 0
    try:
        data = whois.whois(domaine)
    except Exception as e:
        if verbose: print(f"  [!] √âchec de la requ√™te WHOIS : {e}")
        return 0

    if not data or not data.get('creation_date'):
        if verbose: print("  [!] Donn√©es WHOIS invalides ou incompl√®tes.")
        return 0

    privacy_keywords = ["privacy", "whoisguard", "redacted", "protection", "proxy"]
    registrant_info = str(data.get('registrant_name', '')) + str(data.get('org', ''))
    if any(keyword in registrant_info.lower() for keyword in privacy_keywords):
        if verbose: print("  [+] Protection de la confidentialit√© WHOIS d√©tect√©e : +5 pts")
        score += 5
    elif verbose: print("  [-] Pas de protection de confidentialit√© d√©tect√©e.")

    now = datetime.now()
    updated_date = data.get('updated_date')
    if isinstance(updated_date, list): updated_date = updated_date[0]
    creation_date = data.get('creation_date')
    if isinstance(creation_date, list): creation_date = creation_date[0]

    if updated_date and (now - updated_date) < timedelta(days=30):
        if verbose: print(f"  [+] Domaine mis √† jour r√©cemment ({updated_date.date()}) : +10 pts")
        score += 10
    elif creation_date and (now - creation_date) < timedelta(days=90):
        if verbose: print(f"  [+] Domaine cr√©√© r√©cemment ({creation_date.date()}) : +5 pts")
        score += 5
    elif verbose: print("  [-] Pas de mise √† jour ou cr√©ation r√©cente.")

    domain_status = data.get('status', [])
    if isinstance(domain_status, str): domain_status = [domain_status]
    found_hold = False
    for s in domain_status:
        if "clienthold" in s.lower():
            if verbose: print(f"  [+] Statut 'clientHold' trouv√© : +10 pts")
            score += 10
            found_hold = True
            break
    if not found_hold and verbose: print("  [-] Aucun statut 'clientHold' trouv√©.")

    return score

def calculerScoreParking(domaine: str, verbose: bool = False) -> int:
    """Orchestre les analyses et calcule le score final."""
    if verbose: print(f"Lancement de l'analyse compl√®te pour {domaine}...")
    score_contenu = analyserContenu(domaine, verbose=verbose)
    score_technique = analyserTechnique(domaine, verbose=verbose)
    score_contextuel = analyserContextuel(domaine, verbose=verbose)
    score_total = score_contenu + score_technique + score_contextuel
    return min(score_total, 100)

# --- BLOC D'EX√âCUTION AUTONOME ---

def main():
    """Point d'entr√©e pour l'ex√©cution en ligne de commande."""
    parser = argparse.ArgumentParser(
        description="Calcule le score de parking d'un nom de domaine.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument("domaine", help="Le nom de domaine √† analyser (ex: exemple.com).")
    parser.add_argument("-v", "--verbose", action="store_true", help="Affiche le d√©tail des tests et des points attribu√©s.")
    args = parser.parse_args()

    if '.' not in args.domaine:
        print(f"Erreur : '{args.domaine}' ne semble pas √™tre un nom de domaine valide.", file=sys.stderr)
        sys.exit(1)

    score = calculerScoreParking(args.domaine, verbose=args.verbose)

    if args.verbose:
        print("\n" + "="*40)
        print(f"SCORE DE PARKING FINAL POUR {args.domaine.upper()}")
        print(f"Score : {score}/100")
        print("="*40)
    else:
        print(f"Score de parking pour {args.domaine}: {score}/100")

if __name__ == "__main__":
    main()
